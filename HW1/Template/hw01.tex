	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%  Template for homework of Introduction to Machine Learning.
%
%  Fill in your name, lecture number, lecture date and body
%  of homework as indicated below.
%         
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[11pt,letter,notitlepage]{article}
%Mise en page
\usepackage[left=2cm, right=2cm, lines=45, top=0.8in, bottom=0.7in]{geometry}
\usepackage{fancyhdr}
\usepackage{fancybox}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{algorithmic}
\renewcommand{\headrulewidth}{1.5pt}
\renewcommand{\footrulewidth}{1.5pt}
\newcommand\Loadedframemethod{TikZ}
\usepackage[framemethod=\Loadedframemethod]{mdframed}
\usepackage{amssymb,amsmath}
\usepackage{amsthm}
\usepackage{thmtools}
\usepackage{bm}
\setlength{\topmargin}{0pt}
\setlength{\textheight}{9in}
\setlength{\headheight}{0pt}
\setlength{\oddsidemargin}{0.25in}
\setlength{\textwidth}{6in}
%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%% Define math operator %%%%%
%%%%%%%%%%%%%%%%%%%%%%%%
\DeclareMathOperator*{\argmin}{\bf argmin}
\DeclareMathOperator*{\relint}{\bf relint\,}
\DeclareMathOperator*{\dom}{\bf dom\,}
\DeclareMathOperator*{\intp}{\bf int\,}
%%%%%%%%%%%%%%%%%%%%%%%
\setlength{\topmargin}{0pt}
\setlength{\textheight}{9in}
\setlength{\headheight}{0pt}
\setlength{\oddsidemargin}{0.25in}
\setlength{\textwidth}{6in}
\pagestyle{fancy}
%%%%%%%%%%%%%%%%%%%%%%%%
%% Define the Exercise environment %%
%%%%%%%%%%%%%%%%%%%%%%%%
\mdtheorem[
topline=false,
rightline=false,
leftline=false,
bottomline=false,
leftmargin=-10,
rightmargin=-10
]{exercise}{\textbf{Exercise}}
%%%%%%%%%%%%%%%%%%%%%%%
%% End of the Exercise environment %%
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%
%% Define the Problem environment %%
%%%%%%%%%%%%%%%%%%%%%%%%
\mdtheorem[
topline=false,
rightline=false,
leftline=false,
bottomline=false,
leftmargin=-10,
rightmargin=-10
]{problem}{\textbf{Problem}}
%%%%%%%%%%%%%%%%%%%%%%%
%% End of the Exercise environment %%
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
%% Define the Solution Environment %%
%%%%%%%%%%%%%%%%%%%%%%%
\declaretheoremstyle
[
spaceabove=0pt,
spacebelow=0pt,
headfont=\normalfont\bfseries,
notefont=\mdseries,
notebraces={(}{)},
headpunct={:\;},
headindent={},
postheadspace={ },
bodyfont=\normalfont,
qed=$\blacksquare$,
preheadhook={\begin{mdframed}[style=myframedstyle]},
postfoothook=\end{mdframed},
]{mystyle}
\declaretheorem[style=mystyle,title=Solution]{solution}
\mdfdefinestyle{myframedstyle}{%
	topline=false,
	rightline=false,
	leftline=false,
	bottomline=false,
	skipabove=-6ex,
	leftmargin=-10,
	rightmargin=-10,
	backgroundcolor=black!5}
%%%%%%%%%%%%%%%%%%%%%%%
%% End of the Solution environment

\renewcommand{\eqref}[1]{Eq.~(\ref{#1})}
\newcommand{\figref}[1]{Fig.~\ref{#1}}


\newcommand{\proj}[2]{\textbf{P}_{#2} (#1)}
\newcommand{\lspan}[1]{\textbf{span}  (#1)  }
\newcommand{\rank}[1]{ \textbf{rank}  (#1)  }
\newcommand{\tr}{ \operatorname{tr}  }
\newcommand{\RNum}[1]{\uppercase\expandafter{\romannumeral #1\relax}}

\newcommand{\mb}[1]{\mathbf{#1}}

\DeclareMathOperator*{\cl}{\bf cl\,}
\DeclareMathOperator*{\bd}{\bf bd\,}
\DeclareMathOperator*{\conv}{\bf conv\,}
\DeclareMathOperator*{\epi}{\bf epi\,}

% Definition environment	
\theoremstyle{definition}	
\newtheorem{definition}{Definition}	


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%           Homework info.             %%
\newcommand{\posted}{\text{Sep. 28th, 2025}}       			%%% FILL IN POST DATE HERE
\newcommand{\due}{\text{Oct. 16th, 2025}} 			%%% FILL IN Due DATE HERE
\newcommand{\hwno}{\text{1}} 		           			%%% FILL IN LECTURE NUMBER HERE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%    Put your information here   %%
\newcommand{\name}{\text{San Zhang}}  	          			%%% FILL IN YOUR NAME HERE
\newcommand{\id}{\text{PBXXXXXXXX}}		       			%%% FILL IN YOUR ID HERE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \lhead{
% 	\textbf{\name}
% }
% \rhead{
% 	\textbf{\id}
% }
\chead{\textbf{
		Homework \hwno
}}


\begin{document}
	\vspace*{-4\baselineskip}
	\thispagestyle{empty}
	
	
	\begin{center}
		{\bf\large Introduction to Machine Learning}\\
		{Fall 2025}\\
		University of Science and Technology of China
	\end{center}
	
	\noindent
	Lecturer: Zhihui Li, Xiaojun Chang  			 %%% FILL IN LECTURER HERE
	\hfill
	Homework \hwno             			
	\\
	Posted: \posted
	\hfill
	Due: \due
%	Name: \name             			
%	\hfill
%	ID: \id						
%	\hfill
	
	\noindent
	\rule{\textwidth}{2pt}
	
	\medskip
	
	
	
	
	
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%% BODY OF HOMEWORK GOES HERE
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\textbf{Notice, }to get the full credits, please present your solutions step by step.

    \begin{exercise}[Limit and Limit Points]
\begin{enumerate}
    \item Show that $\{\mathbf{x}_n\}$ in $\mathbb{R}^n$ converges to $\mathbf{x}\in \mathbb{R}^n$ if and only if $\{\mathbf{x}_n\}$ is bounded and has a unique limit point $\mathbf{x}$.
    \item (\textbf{Limit Points of a Set}). Let $C$ be a subset of $\mathbb{R}^n$. A point $\mathbf{x}\in \mathbb{R}^n$ is called a limit point of $C$ if there is a sequence $\{\mathbf{x}_n\}$ in $C$ such that $\mathbf{x}_n\to \mathbf{x}$ and $\mathbf{x}_n \not=\mathbf{x}$ for all positive integers $n$. If $\mathbf{x}\in C$ and $\mathbf{x}$ is not a limit point of $C$, then $\mathbf{x}$ is called an isolated point of $C$. Let $C^\prime$ be the set of limit points of the set $C$. Please show the following statements.
    \begin{enumerate}
        \item If $C = (0,1)\cup\{2\}\subset \mathbb{R}$, then $C^\prime =[0,1]$ and $x=2$ is an isolated point of $C$.
        \item  The set $C^\prime$ is closed.
    \end{enumerate}
\end{enumerate}
\end{exercise}

\begin{solution} \textbf{Limit and Limit Points}
\begin{enumerate}
\item 
\item
\begin{enumerate}
	\item 
	\item
\end{enumerate}
\end{enumerate}
\end{solution}

\newpage

\begin{exercise}[Norms]
    In this exercise, we will give some examples of norms and a useful theorem related to norms in \textbf{finite} dimensional vector space.
    \begin{enumerate}
        \item \textbf{$l_p$ norm:} The $l_p$ norm is defined by
        \begin{align*}
			\|\mathbf{x}\|_p = \left(\sum_{i=1}^n |x_i|^p\right)^{1/p}
		\end{align*}
		where $\mathbf{x}=(x_1,\dots,x_n)\in \mathbb{R}^n$ and $p\ge 1$. 
		\begin{enumerate}
			\item Please show that the $l_p$ norm is a norm.
			\item Please show that the following equality.
			\begin{align*}
				\lim_{p\rightarrow \infty}\|\mathbf{x}\|_p = \|\mathbf{x}\|_{\infty} = \max_{1\le i\le n}|x_i|.
			\end{align*}
			The $l_{\infty}$ norm is defined as above.
		\end{enumerate}
		\item \textbf{Operator norms:} Suppose that $\mathbf{A}\in \mathbb{R}^{m\times n}$, which can be viewed as a linear transformation from $\mathbb{R}^n$ to $\mathbb{R}^m$. Please show the following operator norms' equality.
		\begin{enumerate}
			\item Let $\|\mathbf{A}\|_1 = \sup_{\mathbf{x}\in \mathbb{R}^n, \mathbf{x}\not=\mathbf{0}}\frac{\|\mathbf{Ax}\|_1}{\|\mathbf{x}\|_1}$. Please show that
			\begin{align*}
				\|\mathbf{A}\|_1 = \max_{1\le j\le n}\sum_{i=1}^m|a_{ij}|.
			\end{align*}
			\item Let $\|\mathbf{A}\|_{\infty} = \sup_{\mathbf{x}\in \mathbb{R}^n, \mathbf{x}\not=\mathbf{0}}\frac{\|\mathbf{Ax}\|_{\infty}}{\|\mathbf{x}\|_{\infty}}$. Please show that
			\begin{align*}
				\|\mathbf{A}\|_{\infty} = \max_{1\le i\le m}\sum_{j=1}^n|a_{ij}|.
			\end{align*}
		\end{enumerate}
		\item \textbf{(Optional) Dual norm:} Let $\|\cdot\|$ be a norm on $\mathbb{R}^n$. The dual norm of $\|\cdot\|$ is defined by
		\begin{align*}
			\|\mathbf{x}\|_* = \sup_{\mathbf{y}\in \mathbb{R}^n, \|\mathbf{y}\|\le 1}\mathbf{y}^{\top}\mathbf{x}.
		\end{align*}
		\begin{enumerate}
			\item Please show that the dual of the Euclidean norm is the Euclidean norm itself. i.e., 
			\begin{align*}
				\sup_{\mathbf{y}\in \mathbb{R}^n, \|\mathbf{y}\|_2\le 1}\mathbf{y}^{\top}\mathbf{x} = \|\mathbf{x}\|_2.
			\end{align*}
			\item Please show that the dual of the $l_1$ norm is the $l_{\infty}$ norm. i.e.,
			\begin{align*}
				\sup_{\mathbf{y}\in \mathbb{R}^n, \|\mathbf{y}\|_1\le 1}\mathbf{y}^{\top}\mathbf{x} = \|\mathbf{x}\|_{\infty}.
			\end{align*}
		\end{enumerate}
    \end{enumerate}
\end{exercise}

\newpage

\begin{exercise}[Open and Closed Sets]
    The norm ball $\{\mathbf{y} \in \mathbb{R}^n:\|\mathbf{y}-\mathbf{x}\|_2<r, \mathbf{x}\in \mathbb{R}^n\}$ is denoted by $B_r(\mathbf{x})$.
    \begin{enumerate}
        \item Given a set $C \subset \mathbb{R}^n$, please show the following are equivalent.
        \begin{enumerate}
            \item The set $C$ is closed; that is $\cl C=C$.
            \item The complement of $C$ is open.
            \item If $B_{\epsilon}(\mathbf{x})\cap C \not=\emptyset$ for every $\epsilon>0$, then $\mathbf{x}\in C$.
        \end{enumerate}
        \item Given $A\subset\mathbb{R}^n$, a set $C\subset A$ is called open in $A$ if $$C=\{\mathbf{x}\in C: B_{\epsilon}(\mathbf{x})\cap A \subset C\,\text{for some}\, \epsilon>0\}.$$
        A set $C$ is said to be closed in $A$ if $A\setminus C$ is open in $A$.
        \begin{enumerate}
            \item Let $B= [0,1] \cup \{2\}$.  Please show that $[0,1]$ is not an open set in $\mathbb{R}$, while it is both open and closed in $B$.
            \item Please show that a set $C \subset A$ is open in $A$ if and only if $C=A\cap U$, where $U$ is open in $\mathbb{R}^n$.
        \end{enumerate}

    \end{enumerate}
\end{exercise}

\newpage	
	\begin{exercise}[Projection ]
		Let $\mathbf{A}\in\mathbb{R}^{m\times n}$ and $\mathbf{x} \in \mathbb{R}^m$. Define
		\begin{align*}
			\proj{\mathbf{x}}{\mathbf{A}} = \argmin_{\mathbf{z}\in\mathbb{R}^m}\,\{\|\mathbf{x}-\mathbf{z}\|_2: \mathbf{z}\in\mathcal{C}(\mathbf{A})\}.   
		\end{align*}
		We call $\proj{\mathbf{x}}{\mathbf{A}}$ the projection of the point $\mathbf{x}$ onto the column space of $\mathbf{A}$. 
		\begin{enumerate}
			\item Please show that $\mathbf{P}_{\mathbf{A}}(\mathbf{x})$ is unique for any $\mathbf{x} \in \mathbb{R}^m$. 
			\item Let $\mathbf{v}_i \in \mathbb{R}^n$, $i=1,\ldots,d$ with $d\leq n$, which are linearly independent.
			\begin{enumerate}
				\item For any $\mathbf{w}\in \mathbb{R}^n$, please find $\proj{\mathbf{w}}{\mathbf{v}_1}$, which is the projection of $\mathbf{w}$ onto the subspace spanned by $\mathbf{v}_1$.  
				\item Please show $\proj{\cdot}{\mathbf{v}_1}$ is a linear map, i.e.,
				\begin{align*}
					\proj{\alpha\mathbf{u}+\beta\mathbf{w}}{\mathbf{v}_1}=\alpha\proj{\mathbf{u}}{\mathbf{v}_1} + \beta \proj{\mathbf{w}}{\mathbf{v}_1},
				\end{align*}
				where $\alpha,\beta\in\mathbb{R}$ and $\mathbf{w}\in\mathbb{R}^n$.
				\item Please find the projection matrix corresponding to the linear map $\proj{\cdot}{\mathbf{v}_1}$, i.e., find the matrix $\mathbf{H}_1\in\mathbb{R}^{n\times n}$ such that
				\begin{align*}
					\proj{\mathbf{w}}{\mathbf{v}_1}=\mathbf{H}_1\mathbf{w}.
				\end{align*}
				\item Let $\mathbf{V}=(\mathbf{v}_1,\ldots,\mathbf{v}_d)$. 
				\begin{enumerate}
					\item For any $\mathbf{w}\in \mathbb{R}^n$, please find $\proj{\mathbf{w}}{\mathbf{V}}$ and the corresponding projection matrix $\mathbf{H}$.
					\item Please find $\mathbf{H}$ if we further assume that $\mathbf{v}_i^{\top}\mathbf{v}_j=0$, $\forall\,i\neq j$.
				\end{enumerate}
			\end{enumerate}
			
			\item  
			\begin{enumerate}
				\item Suppose that 
				\begin{align*}
					\mathbf{A} = \left[
					\begin{matrix}
						1 & 0\\
						0 & 1
					\end{matrix}
					\right] .
				\end{align*}
				What are the coordinates of $\mathbf{P}_{\mathbf{A}}(\mathbf{x})$ with respect to the column vectors in $\mathbf{A}$ for any $\mathbf{x} \in \mathbb{R}^2$? Are the coordinates unique?
				\item Suppose that
				\begin{align*}
					\mathbf{A} = \left[
					\begin{matrix}
						1 & 2\\
						1 & 2
					\end{matrix}
					\right] .
				\end{align*}
				What are the coordinates of $\mathbf{P}_{\mathbf{A}}(\mathbf{x})$ with respect to the column vectors in $\mathbf{A}$ for any $\mathbf{x} \in \mathbb{R}^2$? Are the coordinates unique?
			\end{enumerate}
			
			\item A matrix $\mathbf{P}$ is called a projection matrix if $\mathbf{P}\mathbf{x}$ is the projection of $\mathbf{x}$ onto $\mathcal{C}(\mathbf{P})$ for any $\mathbf{x}$.
			\begin{enumerate}
				\item Let $\lambda$ be the eigenvalue of $\mathbf{P}$. Show that $\lambda$ is either $1$ or $0$. (\emph{Hint: you may want to figure out what the eigenspaces corresponding to $\lambda=1$ and $\lambda=0$ are, respectively.})
				\item Show that $\mathbf{P}$ is a projection matrix if and only if $\mathbf{P}^2 = \mathbf{P}$ and $\mathbf{P}$ is symmetric.
			\end{enumerate}
			
			\item Let $\mathbf{B} \in \mathbb{R}^{m\times s}$ and $\mathcal{C}(\mathbf{B}) $ be its column space. Suppose that $\mathcal{C}(\mathbf{B})$ is a proper subspace of $ \mathcal{C}(\mathbf{A})$. 
			Is $\proj{\mathbf{x}}{\mathbf{B}}$ the same as $\proj{\proj{\mathbf{x}}{\mathbf{A}}}{\mathbf{B}}$? Please show your claim rigorously.
		\end{enumerate}
	\end{exercise}

\newpage
	\begin{exercise}[Derivatives with matrices]
	
	\begin{definition}[Differentiability]\cite{Tao}\label{def:diff}
	    Let $f:\mathbb{R}^n\rightarrow\mathbb{R}^m$ be a function, $\mathbf{x}_0\in\mathbb{R}^n$ be a point, and let $L:\mathbb{R}^n\rightarrow\mathbb{R}^m$ be a linear transformation. We say that $f$ is \emph{differentiable at $\mathbf{x}_0$ with derivative $L$} if we have
	    \begin{align*}
	        \lim_{\mathbf{x}\rightarrow\mathbf{x}_0;\mathbf{x}\neq\mathbf{x}_0}\frac{\|f(\mathbf{x})-f(\mathbf{x}_0)-L(\mathbf{x}-\mathbf{x}_0)\|_2}{\|\mathbf{x}-\mathbf{x}_0\|_2}=0.
	    \end{align*}
	    We denote this derivative by $f'(\mathbf{x}_0)$.
	\end{definition}
		\begin{enumerate}
			\item 	Let $\mathbf{x},\mathbf{a}\in \mathbb{R}^n$ and $\mathbf{y}\in \mathbb{R}^m$. Consider the functions as follows. Please show that they are differentiable and find $f'(\mathbf{x})$.
			\begin{enumerate}
				\item[(a)] $f(\mathbf{x}) = \mathbf{a}^{\top}\mathbf{x}$.
				\item[(b)] $f(\mathbf{x}) = \mathbf{x}^{\top}\mathbf{x}$.
				
			\end{enumerate}
            \item Consider a differentiable function $f:\mathbb{R}^n\to\mathbb{R}^m$. The \textbf{Jacobian Matrix with denominator layout} is defined by:
            \begin{align*}
                \frac{\partial f}{\partial \mathbf{x}} = \left[
                \begin{matrix}
                    \displaystyle \frac{\partial f_1 (\mathbf{x})}{\partial x_1} & \displaystyle\frac{\partial f_2 (\mathbf{x})}{\partial x_1} & \cdots & \displaystyle\frac{\partial f_m (\mathbf{x})}{\partial x_1} \\
                    \displaystyle\frac{\partial f_1 (\mathbf{x})}{\partial x_2} & \displaystyle\frac{\partial f_2 (\mathbf{x})}{\partial x_2} & \cdots & \displaystyle\frac{\partial f_m (\mathbf{x})}{\partial x_2} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    \displaystyle \frac{\partial f_1 (\mathbf{x})}{\partial x_n} & \displaystyle\frac{\partial f_2 (\mathbf{x})}{\partial x_n} & \cdots & \displaystyle\frac{\partial f_m (\mathbf{x})}{\partial x_n}
                \end{matrix}\right].
            \end{align*}
            Please show that
            \begin{align*}
                L(\mathbf{x} - \mathbf{x}_0) = \left( \frac{\partial f}{\partial \mathbf{x}} \right)^\top (\mathbf{x} - \mathbf{x}_0),
            \end{align*}
            where $L:\mathbb{R}^n\to\mathbb{R}^m$ is the derivative in Definition \ref{def:diff}.
			\item Please follow Definition \ref{def:diff} and give the definition of the differentiability of the functions $f:\mathbb{R}^{n\times n}\rightarrow\mathbb{R}$.
			\item Let $f(\mathbf{X})=\tr(\mathbf{A}^{\top}\mathbf{X})$, where $\mathbf{A},\mathbf{X}\in\mathbb{R}^{n\times m}$, and $\tr(\cdot)$ denotes the trace of a matrix. Please discuss the differentiability of $f$ and find $f'$ if it is differentiable.
			\item (Optional)~ Let $f(\mathbf{X}) = \det(\mathbf{X})$, where $\det(\mathbf{X})$ is the determinant of $\mathbf{X} \in \mathbb{R}^{n \times n}$. Please discuss the differentiability of $f$ rigorously according to your definition in the last part. If $f$ is differentiable, please find $f'(\mathbf{X})$.
			\item (Optional) ~ Let $\mathbf{S}_{++}^n$ be the space of all positive definite $n\times n$ matrices. Please show the function $f: \mathbf{S}_{++}^{n} \rightarrow \mathbb{R}$ defined by $f(\mathbf{X})=\tr{\mathbf{X}^{-1}}$ is differentiable on $ \mathbf{S}_{++}^{n} $. (Hint: Expand the expression $(\mathbf{X}+t\mathbf{Y})^{-1}$ as a power series.)
		\end{enumerate}
	\end{exercise}

\newpage
\begin{exercise}[Linear Space]
\begin{enumerate}
    \item Let $P_n[x]$ be the set of all polynomials on $\mathbb{R}$ with degree at most $n$. Show that $P_n[x]$ is a linear space.

    \item A real symmetric matrix $\mathbf{A} \in \mathbb{R}^{n\times n}$ is called \emph{positive definite}, written $\mathbf A \succ \mathbf 0$, if for all $\mathbf x \in \mathbb{R}^n, \mathbf x\neq \mathbf 0$,
    \[
    \mathbf x^\top\mathbf A \mathbf x > 0.
    \]
    Let the set of all positive definite matrices be
    \[
    \mathbb S^n_{++} := \Big\{\mathbf A \in \mathbb R^{n\times n} : \mathbf A = \mathbf A^\top,\;\mathbf x^\top \mathbf A \mathbf x > 0\ \text{for all }\mathbf x\neq \mathbf 0\Big\}.
    \]
    Is $\mathbb S^n_{++}$ a linear subspace of $\mathbb R^{n\times n}$? Please show your conclusion in detail.
    
\end{enumerate}
    
\end{exercise}

\newpage
	\begin{exercise}[Basis and Coordinates]
		Suppose that $\{\mathbf{a}_1, \mathbf{a}_2,\dots,\mathbf{a}_n\}$ is a basis of an $n$-dimensional vector space $V$.
		\begin{enumerate}
			\item Show that $\{\lambda_1 \mathbf{a}_1, \lambda_2 \mathbf{a}_2, \dots, \lambda_n\mathbf{a}_n\}$ is also a basis of $V$ for nonzero scalars $\lambda_1,\lambda_2, \dots, \lambda_n$.
			\item Let $V =\mathbb{R}^n$, $\mathbf{A}=(\mathbf{a}_1,\mathbf{a}_2, \dots, \mathbf{a}_n)\in\mathbb{R}^{n\times n}$ and $\mathbf{B}=(\mathbf{b}_1,\mathbf{b}_2,\dots, \mathbf{b}_n)\in\mathbb{R}^{n\times n}$. $(\mathbf{b}_1,\mathbf{b}_2,\dots, \mathbf{b}_n) = (\mathbf{a}_1,\mathbf{a}_2, \dots, \mathbf{a}_n)\mathbf{P}$, where $\mathbf{P}\in \mathbb{R}^{n\times n}$ and $\mathbf{b}_i\in \mathbb{R}^n$, for any $i\in\{1,\dots,n\}$. Show that $\{ \mathbf{b}_1, \mathbf{b}_2, \dots, \mathbf{b}_n\}$ is also a basis of $V$ for any invertible  matrix $\mathbf{P}$.
			\item Suppose that the coordinate of a vector $\mathbf{v}$ under the basis $\{\mathbf{a}_1,  \mathbf{a}_2,\dots,\mathbf{a}_n\}$ is $\mathbf{x}=(x_1,x_2,\dots x_n)$.
			\begin{enumerate}
				\item What is the coordinate of $\mathbf{v}$ under $\{\lambda_1 \mathbf{a}_1, \lambda_2 \mathbf{a}_2, \dots, \lambda_n\mathbf{a}_n\}$?
				
				\item What are the coordinates of $\mathbf{w} = \mathbf{a}_1+\dots + \mathbf{a}_n$ under $\{\mathbf{a}_1, \mathbf{a}_2,\dots,\mathbf{a}_n\}$ and $\{\lambda_1 \mathbf{a}_1, \lambda_2 \mathbf{a}_2, \dots, \lambda_n\mathbf{a}_n\}$? Note that  $\lambda_i \neq 0$ for any $i\in \{1,\dots,n\}$.
			\end{enumerate}

                \item Suppose $\mathbf{a}=(1,0)$, $\mathbf{b}=(0,1)$ and $\mathbf{c}=(-1,0)$ are three unit vectors in two-dimensional space. $\mathbf{v}=(x,y)$ is a vector in two-dimensional space.
                \begin{enumerate}
                    \item Please find the coordinate of $\mathbf{v}$ under basis $\{\mathbf{c}, \mathbf{b}\}$? Is the coordinate unique?
                    \item Please find all the possible combination coefficients of $\mathbf{v}$ under vectors $\mathbf{a}$, $\mathbf{b}$ and $\mathbf{c}$, i.e., $\mathbf{v} = x'\mathbf{a}+y'\mathbf{b}+z'\mathbf{c}$. 
                    \item (\textbf{Bonus}) Each set of combination coefficients $(x',y',z')$ in (b) forms a vector in $\mathbb{R}^3$. Please find the combination coefficients with minimum $\ell_1$-norm.
                \end{enumerate}

		\end{enumerate}
	\end{exercise}	

	\newpage
	\begin{exercise}[Rank of matrices ]
		Let $\mathbf{A} \in \mathbb{R}^{m\times n}$ and $\mathbf{B}\in \mathbb{R}^{n\times p}$.
		\begin{enumerate}
			\item Please show that
			\begin{enumerate}
				\item $\rank{\mathbf{A}} = \rank{\mathbf{A}^{\top}} = \rank{\mathbf{A}^{\top}\mathbf{A}}= \rank{\mathbf{A}\mathbf{A}^{\top}}$;
				\item $\rank{\mathbf{A}\mathbf{B}} \leq \rank{\mathbf{A}}$; (please give an example when the equality holds)
			\end{enumerate}
			\item The \emph{column space} of $\mathbf{A}$ is defined by
			\begin{align*}
				\mathcal{C}(\mathbf{A} ) = \{ \mathbf{y}\in \mathbb{R}^m : \mathbf{y} = \mathbf{Ax},\,\mathbf{x}\in\mathbb{R}^n\}.
			\end{align*}
			The \emph{null space} of $\mathbf{A}$ is defined by
			\begin{align*}
				\mathcal{N}(\mathbf{A})  = \{ \mathbf{x}\in \mathbb{R}^n : \mathbf{Ax}=0\}.
			\end{align*}
			Notice that, the rank of $\mathbf{A}$ is the dimension of the column space of $\mathbf{A}$.
			
			Please show that
			\begin{enumerate}
				\item $\rank{\mathbf{A}} = \dim(\mathcal{C}(\mathbf{A})$;
				\item $\rank{\mathbf{A}} + \dim ( \mathcal{N}( \mathbf{A} ) ) = n$.
			\end{enumerate}
			\item Given that
			\begin{align}\label{eqn:rankaba}
				\rank{\mathbf{AB}}=\rank{\mathbf{B}}-\dim(\mathcal{C}(\mathbf{B})\cap \mathcal{N}(\mathbf{A})).
			\end{align}
			Please show the results in 1.(b) by \eqref{eqn:rankaba}.
		\end{enumerate}
	\end{exercise}
	
\newpage
    \begin{exercise}[Properties of Eigenvalues and Singular Values]
    \begin{enumerate}
        \item Suppose the maximum eigenvalue, minimum eigenvalue and maximum singular value of a given symmetric matrix $\mathbf{A}\in S^n$ are denoted by $\lambda_{\max}(\mathbf{A})$ and $ \lambda_{\min}(\mathbf{A})$, respectively. Please show that
        \begin{align*}
            \lambda_{\max}(\mathbf{A})=\sup_{\mathbf{x}\in\mathbb{R}^n, \mathbf{x}\not=\mathbf{0}} \frac{\mathbf{x}^\top\mathbf{A}\mathbf{x}}{\mathbf{x}^\top\mathbf{x}},\,\,\,\,\,
            \lambda_{\min}(\mathbf{A})=\inf_{\mathbf{x}\in\mathbb{R}^n, \mathbf{x}\not=\mathbf{0}} \frac{\mathbf{x}^\top\mathbf{A}\mathbf{x}}{\mathbf{x}^\top\mathbf{x}}.
        \end{align*}

        \item (\textbf{Optional}) ~Suppose $B=(bij)\in \mathbb{R}^{m\times n}\mathbf{B}=(b_{ij})\in \mathbb{R}^{m\times n}$ with maximum singular value $\max\sigma_{\max}(\mathbf{B})$.
        \begin{enumerate}
            \item Let $\|\mathbf{B}\|_2:=\sup_{\mathbf{x}\in\mathbb{R}^n, \mathbf{x}\not=\mathbf{0}}\frac{\|\mathbf{Bx}\|_2}{\|\mathbf{x}\|_2}$. Please show that
             \begin{align*}
            \sigma_{\max}(\mathbf{B})=\|\mathbf{B}\|_2.
            \end{align*}

            \item Please show that
        \begin{align*}
            \sigma_{\max}(\mathbf{B})=\sup_{\mathbf{x}\in\mathbb{R}^m, \mathbf{y}\in\mathbb{R}^n, \mathbf{x},\mathbf{y}\not=0}\frac{\mathbf{x}^\top \mathbf{B}\mathbf{y}}{\|\mathbf{x}\|_2\|\mathbf{y}\|_2}.
        \end{align*}
        \end{enumerate}
    \end{enumerate}
    \end{exercise}

\newpage
\begin{exercise}[Matrix SVD Decomposition and Pseudoinverse]
    \begin{enumerate}
    \item 
    For any real matrix $\mathbf{A}\in\mathbb{R}^{n\times m}$, the \textbf{Moore-Penrose generalized inverse} (or pseudoinverse) of $\mathbf{A}$, denoted by $\mathbf{A}^+\in\mathbb{R}^{m\times n}$, is a matrix that satisfies the following four conditions:

        \begin{enumerate}
            \item $\mathbf{A}\mathbf{A}^+\mathbf{A} = \mathbf{A}$ \hfill (Consistency condition)
            \item $\mathbf{A}^+\mathbf{A}\mathbf{A}^+ = \mathbf{A}^+$ \hfill (Reflexivity condition)
            \item $(\mathbf{A}\mathbf{A}^+)^\top = \mathbf{A}\mathbf{A}^+$ \hfill (Symmetry condition 1)
            \item $(\mathbf{A}^+\mathbf{A})^\top = \mathbf{A}^+\mathbf{A}$ \hfill (Symmetry condition 2)
        \end{enumerate}
    Suppose that the matrix \( \mathbf{A} \) can be decomposed via Singular Value Decomposition (SVD) as \( \mathbf{A} = \mathbf{U}\boldsymbol{\Sigma} \mathbf{V}^\top \), Please show that $\mathbf{A}^+ = \mathbf{V}\boldsymbol\Sigma^{+} \mathbf{U}^\top$, where $ \boldsymbol \Sigma^+ \in\mathbb{R}^{m\times n} $ is defined by:
    \[
    \boldsymbol\Sigma^+_{ij} = 
    \begin{cases} 
    \frac{1}{\boldsymbol\Sigma_{ii}} & \text{if } i = j \text{ and } \boldsymbol \Sigma_{ii} \neq 0, \\
    0 & \text{otherwise}.
    \end{cases}
    \]
    
    
    \item \textbf{(Optional)} Please show that $\mathbf{A}^+$ is unique for any matrix $\mathbf{A}\in\mathbb{R}^{n\times m}$.

    \item Consider the linear system $\mathbf{A}\mathbf{x} = \mathbf{b}$ where $\mathbf{A}\in\mathbb{R}^{n\times m}$, $\mathbf{x} \in \mathbb{R}^m$, and $\mathbf{b} \in \mathbb{R}^n$. Please show that if the system has no solution (i.e., $\mathbf{b}$ is not in the column space of $\mathbf{A}$), the least squares solution to the system
    $$
    \arg \min_{\mathbf{x}\in\mathbb{R}^m}\quad \left\Vert \mathbf{A}\mathbf{x} - \mathbf b \right\Vert_2^2,
    $$
    is given by $\mathbf{x} = \mathbf A^ + \mathbf b$, where $\mathbf{A}^+\in\mathbb{R}^{m\times n}$ is the Moore-Penrose generalized inverse of matrix $\mathbf{A}$ defined above.

    (\textbf{Hint}: For any orthogonal matrix $\mathbf{U}\in\mathbb{R}^{n\times n}$ and vector $\mathbf{x}\in\mathbb{R}^n$, then $\|\mathbf{U}\mathbf{x}\|_2 = \|\mathbf{x}\|_2$)
\end{enumerate}
\end{exercise}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	\newpage
	\newpage
    \bibliography{refs}
    \bibliographystyle{abbrv}
	
\end{document}
